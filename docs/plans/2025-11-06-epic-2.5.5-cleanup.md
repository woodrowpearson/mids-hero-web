# Epic 2.5.5: Project Cleanup & JSON Migration Preparation

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Remove all MHD/I12 legacy code, resolve structural conflicts, and prepare codebase for JSON data migration.

**Architecture:** Sequential cleanup with verification at each priority level. Archive before delete. Test after each change.

**Tech Stack:** Python 3.11, FastAPI, SQLAlchemy, PostgreSQL, pytest

---

## Priority 1: Resolve Duplicates & Conflicts (CRITICAL)

### Task 1.1: Audit Backend Core Duplicates

**Files:**
- Audit: `backend/backend/app/core/` vs `backend/app/core/`
- Create: `docs/plans/core-duplication-analysis.md`

**Step 1: Compare directory structures**

```bash
diff -r backend/backend/app/core backend/app/core > /tmp/core_diff.txt
```

Expected: Shows differences between directories

**Step 2: List all files in both locations**

```bash
fd . backend/backend/app/core --type f | sort > /tmp/nested_core.txt
fd . backend/app/core --type f | sort > /tmp/root_core.txt
```

**Step 3: Document findings**

Create `docs/plans/core-duplication-analysis.md`:

```markdown
# Core Directory Duplication Analysis

## Nested Location: backend/backend/app/core/
[List files found]

## Root Location: backend/app/core/
[List files found]

## Differences:
[Document diff output]

## Decision:
- Canonical location: [Choose one]
- Files to merge: [List]
- Files to delete: [List]
```

**Step 4: Find all imports referencing nested core**

```bash
rg "from backend.backend.app.core" --type py > /tmp/nested_imports.txt
rg "import backend.backend.app.core" --type py >> /tmp/nested_imports.txt
```

**Step 5: Commit analysis**

```bash
git add docs/plans/core-duplication-analysis.md
git commit -m "docs: analyze backend core duplication"
```

### Task 1.2: Merge Core Directories

**Files:**
- Modify: `backend/app/core/` (keep this as canonical)
- Delete: `backend/backend/app/core/` (after merge)
- Update: All files with imports (from Step 1.1)

**Step 1: Backup nested core**

```bash
mkdir -p archive/backend-core-nested
cp -r backend/backend/app/core/ archive/backend-core-nested/
```

**Step 2: Merge unique files to canonical location**

```bash
# If nested has unique files:
cp backend/backend/app/core/unique_file.py backend/app/core/
```

**Step 3: Update all imports (automated)**

```bash
# Find and replace all nested imports
fd --type f --extension py --exec sed -i '' 's/from backend\.backend\.app\.core/from backend.app.core/g' {}
fd --type f --extension py --exec sed -i '' 's/import backend\.backend\.app\.core/import backend.app.core/g' {}
```

**Step 4: Verify no nested imports remain**

```bash
rg "backend.backend.app.core" --type py
```

Expected: No results

**Step 5: Delete nested directory**

```bash
rm -rf backend/backend/app/core/
```

**Step 6: Run tests to verify**

```bash
just test
```

Expected: All tests pass

**Step 7: Commit changes**

```bash
git add -A
git commit -m "refactor: consolidate backend.app.core, remove duplicate"
```

### Task 1.3: Fix Import Statements Project-Wide

**Files:**
- Modify: All Python files with updated imports
- Test: `tests/backend/`

**Step 1: Run linter to find issues**

```bash
just lint-fix
```

**Step 2: Verify import paths**

```bash
cd backend && python -c "from app.core.config import settings; print('OK')"
```

Expected: No ImportError

**Step 3: Run full test suite**

```bash
just test
```

Expected: All tests pass

**Step 4: Commit lint fixes**

```bash
git add -A
git commit -m "fix: resolve import paths after core consolidation"
```

### Task 1.4: Archive Legacy Data Directories

**Files:**
- Move: `data/exported/` â†’ `archive/legacy-data/exported/`
- Move: `data/imported/` â†’ `archive/legacy-data/imported/`
- Update: `.gitignore`

**Step 1: Create archive structure**

```bash
mkdir -p archive/legacy-data
```

**Step 2: Move exported data**

```bash
mv data/exported archive/legacy-data/ 2>/dev/null || echo "exported already moved"
```

**Step 3: Move imported data**

```bash
mv data/imported archive/legacy-data/ 2>/dev/null || echo "imported already moved"
```

**Step 4: Update .gitignore**

```bash
echo "archive/" >> .gitignore
```

**Step 5: Verify data directories gone**

```bash
test ! -d data/exported && test ! -d data/imported && echo "âœ… Cleanup complete"
```

Expected: âœ… Cleanup complete

**Step 6: Commit changes**

```bash
git add .gitignore
git add -A
git commit -m "chore: archive legacy data directories"
```

---

## Priority 2: Remove MHD Dependencies

### Task 2.1: Archive MHD Parser Module

**Files:**
- Move: `backend/app/mhd_parser/` â†’ `archive/mhd-parser/`
- Delete: References in other modules

**Step 1: Create archive location**

```bash
mkdir -p archive/mhd-parser
```

**Step 2: Move MHD parser**

```bash
mv backend/app/mhd_parser archive/mhd-parser/
```

**Step 3: Find all MHD imports**

```bash
rg "from backend.app.mhd_parser" --type py > /tmp/mhd_imports.txt
rg "import.*mhd_parser" --type py >> /tmp/mhd_imports.txt
```

**Step 4: Document affected files**

```bash
cat /tmp/mhd_imports.txt
```

**Step 5: Commit archive**

```bash
git add -A
git commit -m "chore: archive MHD parser module"
```

### Task 2.2: Remove MHD Imports from Data Import Module

**Files:**
- Modify: `backend/app/data_import/importers.py`
- Delete: MHDImporter class and references

**Step 1: Read current importers file**

```bash
cat backend/app/data_import/importers.py
```

**Step 2: Create backup**

```bash
cp backend/app/data_import/importers.py backend/app/data_import/importers.py.backup
```

**Step 3: Remove MHD imports and classes**

Edit `backend/app/data_import/importers.py`:
- Remove: `from backend.app.mhd_parser import ...`
- Remove: `class MHDImporter` and all methods
- Keep: Other importer classes

**Step 4: Verify no MHD references**

```bash
rg "mhd|MHD" backend/app/data_import/importers.py
```

Expected: No results

**Step 5: Run import tests**

```bash
pytest tests/backend/data_import/ -v
```

Expected: Tests pass (or are skipped if MHD-specific)

**Step 6: Commit changes**

```bash
git add backend/app/data_import/importers.py
git commit -m "refactor: remove MHD importer from data_import module"
```

### Task 2.3: Remove MHD API Endpoints

**Files:**
- Modify: `backend/app/api/routers/import.py`
- Delete: MHD-related endpoints

**Step 1: List MHD endpoints**

```bash
rg "mhd|i12" backend/app/api/routers/ --type py
```

**Step 2: Edit import router**

Edit `backend/app/api/routers/import.py`:
- Remove endpoints: `/import/mhd`, `/import/i12`, etc.
- Keep: Other import endpoints

**Step 3: Update API tests**

```bash
rg "mhd|i12" tests/backend/api/ --type py
```

Remove or update affected tests.

**Step 4: Verify API still works**

```bash
just dev &
sleep 5
curl http://localhost:8000/api/health
```

Expected: 200 OK

**Step 5: Kill dev server**

```bash
pkill -f "uvicorn"
```

**Step 6: Commit changes**

```bash
git add backend/app/api/routers/
git commit -m "refactor: remove MHD API endpoints"
```

### Task 2.4: Create JSON Import Module

**Files:**
- Create: `backend/app/data_import/json_importer.py`
- Create: `tests/backend/data_import/test_json_importer.py`

**Step 1: Write the failing test**

Create `tests/backend/data_import/test_json_importer.py`:

```python
import pytest
from pathlib import Path
from backend.app.data_import.json_importer import JSONDataImporter


@pytest.fixture
def importer():
    return JSONDataImporter()


def test_json_importer_initialization(importer):
    """Test that JSONDataImporter initializes"""
    assert importer is not None
    assert hasattr(importer, 'import_archetypes')


@pytest.mark.asyncio
async def test_import_archetypes_from_manifest(importer, tmp_path):
    """Test importing archetypes from JSON manifest"""
    # Create test manifest
    manifest = tmp_path / "manifest.json"
    manifest.write_text('{"archetypes": []}')

    result = await importer.import_archetypes(manifest)
    assert result['success'] is True
```

**Step 2: Run test to verify it fails**

```bash
pytest tests/backend/data_import/test_json_importer.py -v
```

Expected: FAIL - "No module named 'backend.app.data_import.json_importer'"

**Step 3: Write minimal implementation**

Create `backend/app/data_import/json_importer.py`:

```python
"""JSON data importer for City of Data"""
import json
from pathlib import Path
from typing import Dict, Any


class JSONDataImporter:
    """Import game data from filtered JSON files"""

    def __init__(self):
        """Initialize the JSON importer"""
        pass

    async def import_archetypes(self, manifest_path: Path) -> Dict[str, Any]:
        """Import archetypes from JSON manifest

        Args:
            manifest_path: Path to manifest.json file

        Returns:
            Dict with success status and imported count
        """
        if not manifest_path.exists():
            return {'success': False, 'error': 'Manifest not found'}

        # Read manifest
        with open(manifest_path) as f:
            data = json.load(f)

        archetypes = data.get('archetypes', [])

        return {
            'success': True,
            'imported': len(archetypes)
        }

    async def import_powersets(self, manifest_path: Path) -> Dict[str, Any]:
        """Import powersets from JSON manifest"""
        return {'success': True, 'imported': 0}

    async def import_powers(self, manifest_path: Path) -> Dict[str, Any]:
        """Import powers from JSON manifest"""
        return {'success': True, 'imported': 0}

    async def import_enhancements(self, manifest_path: Path) -> Dict[str, Any]:
        """Import enhancement sets from JSON manifest"""
        return {'success': True, 'imported': 0}
```

**Step 4: Run test to verify it passes**

```bash
pytest tests/backend/data_import/test_json_importer.py -v
```

Expected: PASS

**Step 5: Commit**

```bash
git add backend/app/data_import/json_importer.py tests/backend/data_import/test_json_importer.py
git commit -m "feat: add JSON data importer module"
```

### Task 2.5: Update Database Models for JSON

**Files:**
- Modify: `backend/app/db/models.py`
- Create: `backend/alembic/versions/XXXX_add_json_metadata.py`

**Step 1: Write the failing test**

Create `tests/backend/db/test_json_metadata.py`:

```python
import pytest
from backend.app.db.models import Power


def test_power_has_source_metadata_field():
    """Test that Power model has source_metadata JSON field"""
    assert hasattr(Power, 'source_metadata')


def test_power_has_tags_array_field():
    """Test that Power model has tags array field"""
    assert hasattr(Power, 'tags')
```

**Step 2: Run test to verify it fails**

```bash
pytest tests/backend/db/test_json_metadata.py -v
```

Expected: FAIL - "Power has no attribute 'source_metadata'"

**Step 3: Update Power model**

Edit `backend/app/db/models.py`:

```python
from sqlalchemy import Column, Integer, String, Numeric, JSON, ARRAY
from sqlalchemy.ext.declarative import declarative_base

# Find the Power class and add these fields:

class Power(Base):
    # ... existing fields ...

    # New JSON metadata fields
    source_metadata = Column(JSON, nullable=True, comment="Raw JSON from source")
    tags = Column(ARRAY(String), default=[], comment="Power interaction tags")
    requires = Column(ARRAY(String), default=[], comment="Power dependencies")
```

**Step 4: Generate migration**

```bash
cd backend
alembic revision --autogenerate -m "Add JSON metadata fields to Power model"
cd ..
```

**Step 5: Review migration file**

```bash
ls -la backend/alembic/versions/ | tail -1
```

**Step 6: Apply migration**

```bash
cd backend
alembic upgrade head
cd ..
```

**Step 7: Run test to verify it passes**

```bash
pytest tests/backend/db/test_json_metadata.py -v
```

Expected: PASS

**Step 8: Commit**

```bash
git add backend/app/db/models.py backend/alembic/versions/
git commit -m "feat: add JSON metadata fields to Power model"
```

---

## Priority 3: Update Claude AI Context

### Task 3.1: Retrain Import Specialist Agent

**Files:**
- Modify: `.claude/modules/import/guide.md`
- Create: `.claude/docs/EPIC_2.5.5/import-specialist-update.md`

**Step 1: Backup current guide**

```bash
cp .claude/modules/import/guide.md .claude/modules/import/guide.md.backup
```

**Step 2: Document required changes**

Create `.claude/docs/EPIC_2.5.5/import-specialist-update.md`:

```markdown
# Import Specialist Update

## Sections to Remove:
- Binary MHD File Parsing
- I12 Format Documentation
- MidsReborn Integration
- Windows VM Setup

## Sections to Add:
- JSON Data Source Overview
- Filtered Data Manifest Structure
- JSON Import Pipeline
- City of Data Architecture
```

**Step 3: Rewrite import guide**

Edit `.claude/modules/import/guide.md`:

```markdown
# Import Module Guide

## Overview
The import system processes JSON game data from the filtered City of Data source located at `filtered_data/`.

## Architecture
- **JSON manifest-driven**: All imports reference `filtered_data/manifest.json`
- **Batch processing**: Imports process data in configurable batch sizes
- **Progress tracking**: Real-time progress with resume capability
- **Validation**: Comprehensive schema validation before database insert

## Key Components

### JSONDataImporter
Primary class for importing JSON data.

Location: `backend/app/data_import/json_importer.py`

Methods:
- `import_archetypes(manifest_path)`: Import character archetypes
- `import_powersets(manifest_path)`: Import power sets
- `import_powers(manifest_path)`: Import individual powers
- `import_enhancements(manifest_path)`: Import enhancement sets

### Data Sources

Filtered data location: `filtered_data/`

Structure:
```
filtered_data/
â”œâ”€â”€ manifest.json              # Master manifest
â”œâ”€â”€ archetypes/               # 15 player archetypes
â”œâ”€â”€ powersets/                # Power set definitions
â”œâ”€â”€ powers/                   # 5,775 individual powers
â””â”€â”€ boost_sets/               # 228 enhancement sets
```

## Usage

### Import All Data
```bash
just json-import-all
```

### Import Specific Category
```bash
just json-import-archetypes
just json-import-powersets
just json-import-powers
just json-import-enhancements
```

### Health Check
```bash
just json-import-health
```

## Implementation Details

### Manifest Structure
```json
{
  "version": "2025.06.17",
  "source": "city_of_data_homecoming",
  "categories": {
    "archetypes": {
      "count": 15,
      "path": "archetypes/"
    },
    "powers": {
      "count": 5775,
      "path": "powers/"
    }
  }
}
```

### Import Flow
1. Read manifest.json
2. Validate manifest schema
3. Process each category sequentially
4. Batch database inserts (100 records/batch)
5. Track progress in import_progress table
6. Handle errors with rollback capability

### Error Handling
- Invalid JSON: Skip file, log error, continue
- Schema mismatch: Log validation errors, skip record
- Database errors: Rollback batch, log error, retry
- Missing files: Log warning, continue with available data

## Testing

Run import tests:
```bash
pytest tests/backend/data_import/ -v
```

Test coverage requirement: >85%

## Related Skills
- @database-specialist: For schema questions
- @backend-specialist: For API integration
```

**Step 4: Verify guide quality**

```bash
cat .claude/modules/import/guide.md | wc -l
```

Expected: Comprehensive guide (100+ lines)

**Step 5: Commit changes**

```bash
git add .claude/modules/import/guide.md .claude/docs/EPIC_2.5.5/
git commit -m "docs: update import specialist guide for JSON workflow"
```

### Task 3.2: Update Context Map Keywords

**Files:**
- Modify: `.claude/context-map.json`

**Step 1: Read current context map**

```bash
cat .claude/context-map.json
```

**Step 2: Update import module keywords**

Edit `.claude/context-map.json`:

```json
{
  "modules": {
    "import": {
      "keywords": [
        "import",
        "importer",
        "json import",
        "city of data",
        "filtered data",
        "archetype import",
        "powerset import",
        "enhancement import",
        "data import",
        "manifest"
      ],
      "exclude_keywords": [
        "mhd",
        "i12",
        "binary",
        "midsreborn",
        "windows vm"
      ],
      "guide": ".claude/modules/import/guide.md",
      "context_files": [
        "backend/app/data_import/json_importer.py",
        "filtered_data/manifest.json"
      ]
    }
  }
}
```

**Step 3: Validate JSON syntax**

```bash
python -m json.tool .claude/context-map.json > /dev/null && echo "âœ… Valid JSON"
```

Expected: âœ… Valid JSON

**Step 4: Commit changes**

```bash
git add .claude/context-map.json
git commit -m "chore: update context map for JSON import workflow"
```

---

## Priority 4: Migrate Justfile Commands

### Task 4.1: Remove MHD Commands

**Files:**
- Modify: `justfile`

**Step 1: List current MHD commands**

```bash
rg "^(i12|mhd)" justfile
```

**Step 2: Backup justfile**

```bash
cp justfile justfile.backup
```

**Step 3: Remove MHD commands**

Edit `justfile` - DELETE these commands:
```just
i12-import:
    # ... remove ...

i12-parse:
    # ... remove ...

mhd-parse:
    # ... remove ...

mhd-validate:
    # ... remove ...

i12-health:
    # ... remove ...
```

**Step 4: Verify removal**

```bash
rg "^(i12|mhd)" justfile
```

Expected: No results

**Step 5: Test remaining commands**

```bash
just --list
```

Expected: No MHD commands listed

**Step 6: Commit changes**

```bash
git add justfile
git commit -m "chore: remove MHD/I12 justfile commands"
```

### Task 4.2: Add JSON Import Commands

**Files:**
- Modify: `justfile`

**Step 1: Add JSON import commands section**

Edit `justfile` - ADD after data import section:

```just
# JSON Data Import Commands
json-import-archetypes:
    @echo "Importing archetypes from JSON..."
    uv run python -m backend.app.data_import.json_importer archetypes

json-import-powersets:
    @echo "Importing powersets from JSON..."
    uv run python -m backend.app.data_import.json_importer powersets

json-import-powers:
    @echo "Importing powers from JSON..."
    uv run python -m backend.app.data_import.json_importer powers

json-import-enhancements:
    @echo "Importing enhancement sets from JSON..."
    uv run python -m backend.app.data_import.json_importer enhancements

json-import-all:
    @echo "Importing all JSON data..."
    @just json-import-archetypes
    @just json-import-powersets
    @just json-import-powers
    @just json-import-enhancements
    @echo "âœ… All JSON data imported"

json-import-health:
    @echo "ðŸ¥ Validating JSON import system..."
    @test -f filtered_data/manifest.json || (echo "âŒ Manifest not found"; exit 1)
    @uv run python scripts/validate_filtered_data.py
    @echo "âœ… JSON import system healthy"
```

**Step 2: Test new commands**

```bash
just --list | grep json-import
```

Expected: Shows all new json-import commands

**Step 3: Test health check**

```bash
just json-import-health
```

Expected: âœ… JSON import system healthy

**Step 4: Commit changes**

```bash
git add justfile
git commit -m "feat: add JSON import justfile commands"
```

### Task 4.3: Update Health Command

**Files:**
- Modify: `justfile`

**Step 1: Find health command**

```bash
rg "^health:" justfile -A 10
```

**Step 2: Update health command**

Edit `justfile` - UPDATE health command:

```just
health:
    @echo "ðŸ¥ Running health checks..."
    @just git-workflow-check
    @echo "Setting up development environment..."
    @python3 scripts/dev.py setup
    @just json-import-health
    @echo "âœ… Health checks passed"
```

**Step 3: Test health command**

```bash
just health
```

Expected: All checks pass including json-import-health

**Step 4: Commit changes**

```bash
git add justfile
git commit -m "chore: update health command to use json-import-health"
```

---

## Priority 5: Evaluate Incomplete Features

### Task 5.1: Assess Calculation Module

**Files:**
- Audit: `backend/app/calc/`
- Create: `.claude/docs/EPIC_2.5.5/calc-module-decision.md`

**Step 1: Check if calc module exists**

```bash
test -d backend/app/calc && echo "EXISTS" || echo "NOT FOUND"
```

**Step 2: List calc module contents**

```bash
fd . backend/app/calc --type f
```

**Step 3: Check test coverage**

```bash
pytest tests/backend/calc/ -v --cov=backend/app/calc --cov-report=term-missing
```

**Step 4: Check for usage in API**

```bash
rg "from backend.app.calc" --type py
rg "import.*calc" --type py | grep backend
```

**Step 5: Document decision**

Create `.claude/docs/EPIC_2.5.5/calc-module-decision.md`:

```markdown
# Calculation Module Assessment

## Current State
- Files found: [List from Step 2]
- Test coverage: [Percentage from Step 3]
- Used by: [Files from Step 4]

## Decision

**IF coverage >70% AND actively used:**
â†’ KEEP: Document and integrate into Epic 3.2

**IF coverage <70% OR unused:**
â†’ ARCHIVE: Move to archive/incomplete-features/calc/

## Recommendation
[State decision and rationale]

## Action Items
- [ ] [Specific next steps based on decision]
```

**Step 6: Commit assessment**

```bash
git add .claude/docs/EPIC_2.5.5/calc-module-decision.md
git commit -m "docs: assess calculation module status"
```

### Task 5.2: Handle Calculation Module Based on Assessment

**Files:**
- Move: `backend/app/calc/` â†’ `archive/incomplete-features/calc/` (if archiving)
- OR Document: `.claude/modules/calculation/guide.md` (if keeping)

**Step 1: Execute decision from Task 5.1**

IF ARCHIVING:
```bash
mkdir -p archive/incomplete-features
mv backend/app/calc archive/incomplete-features/
```

IF KEEPING:
```bash
mkdir -p .claude/modules/calculation
# Create documentation (next step)
```

**Step 2: Update documentation accordingly**

IF ARCHIVING - Create GitHub issue:
```bash
gh issue create \
  --title "Epic 3.2: Implement Calculation Engine" \
  --body "Reimplement calculation module with TDD approach"
```

IF KEEPING - Create guide:
```bash
cat > .claude/modules/calculation/guide.md << 'EOF'
# Calculation Module Guide

## Overview
Calculation engine for build statistics and power effects.

## Current Implementation
[Document what exists]

## Integration Points
[Document how it's used]

## Testing
[Document test coverage]
EOF
```

**Step 3: Commit changes**

```bash
git add -A
git commit -m "chore: handle calculation module per assessment"
```

---

## Priority 6: Verify Cleanup Completeness

### Task 6.1: Create Verification Script

**Files:**
- Create: `scripts/verify_mhd_cleanup.sh`

**Step 1: Write verification script**

Create `scripts/verify_mhd_cleanup.sh`:

```bash
#!/bin/bash
set -e

echo "ðŸ” Searching for MHD references..."

# Search code for MHD/I12 references
rg -i "mhd|i12|midsreborn" \
  --type py \
  --type ts \
  --type tsx \
  --glob "!archive/**" \
  --glob "!*.md" \
  --glob "!docs/**" \
  > /tmp/mhd_refs.txt || true

if [ -s /tmp/mhd_refs.txt ]; then
  echo "âŒ Found MHD references in code:"
  cat /tmp/mhd_refs.txt
  exit 1
else
  echo "âœ… No MHD references found in code"
fi

# Verify deleted directories
if [ -d "backend/app/mhd_parser" ]; then
  echo "âŒ MHD parser directory still exists"
  exit 1
fi

if [ -d "backend/backend/app/core" ]; then
  echo "âŒ Nested backend core directory still exists"
  exit 1
fi

echo "âœ… All deleted directories confirmed removed"

# Verify archive structure
if [ ! -d "archive/mhd-parser" ]; then
  echo "âŒ MHD parser not found in archive"
  exit 1
fi

echo "âœ… Archive structure correct"

echo ""
echo "ðŸŽ‰ Cleanup verification passed!"
```

**Step 2: Make script executable**

```bash
chmod +x scripts/verify_mhd_cleanup.sh
```

**Step 3: Test script**

```bash
./scripts/verify_mhd_cleanup.sh
```

Expected: May fail at this stage - that's OK

**Step 4: Commit script**

```bash
git add scripts/verify_mhd_cleanup.sh
git commit -m "feat: add MHD cleanup verification script"
```

### Task 6.2: Add Verification to Justfile

**Files:**
- Modify: `justfile`

**Step 1: Add verify-cleanup command**

Edit `justfile` - ADD:

```just
# Cleanup Verification
verify-cleanup:
    @echo "Running cleanup verification..."
    @./scripts/verify_mhd_cleanup.sh
```

**Step 2: Test command**

```bash
just verify-cleanup
```

**Step 3: Commit changes**

```bash
git add justfile
git commit -m "feat: add verify-cleanup justfile command"
```

### Task 6.3: Run Final Verification

**Files:**
- None (verification only)

**Step 1: Run comprehensive verification**

```bash
just verify-cleanup
```

Expected: ðŸŽ‰ Cleanup verification passed!

**Step 2: Run all tests**

```bash
just test
```

Expected: All tests pass

**Step 3: Run quality checks**

```bash
just quality
```

Expected: All checks pass

**Step 4: Document verification results**

Create `.claude/docs/EPIC_2.5.5/cleanup-verification-results.md`:

```markdown
# Cleanup Verification Results

Date: [Date]

## Verification Script Output
âœ… No MHD references found in code
âœ… All deleted directories confirmed removed
âœ… Archive structure correct

## Test Results
âœ… All tests passing

## Quality Checks
âœ… All quality checks passing

## Status
Epic 2.5.5 cleanup COMPLETE
```

**Step 5: Commit verification results**

```bash
git add .claude/docs/EPIC_2.5.5/cleanup-verification-results.md
git commit -m "docs: document cleanup verification results"
```

---

## Priority 7: Organizational Housekeeping

### Task 7.1: Reorganize Documentation

**Files:**
- Move: City of Data docs to `.claude/docs/EPIC_2.6/`
- Create: `.claude/docs/EPIC_2.5.5/` (already exists from prior tasks)

**Step 1: Create Epic 2.6 docs directory**

```bash
mkdir -p .claude/docs/EPIC_2.6
```

**Step 2: Move City of Data documentation**

```bash
mv .claude/docs/city-of-data-pruning-plan.md .claude/docs/EPIC_2.6/
mv .claude/docs/city-of-data-structure-map.md .claude/docs/EPIC_2.6/
mv .claude/docs/city-of-data-schema-reference.md .claude/docs/EPIC_2.6/
mv .claude/docs/city-of-data-pruning-strategy.md .claude/docs/EPIC_2.6/
mv .claude/docs/city-of-data-filtering-results.md .claude/docs/EPIC_2.6/
```

**Step 3: Verify moves**

```bash
ls -la .claude/docs/EPIC_2.6/
```

Expected: All city-of-data files listed

**Step 4: Commit reorganization**

```bash
git add -A
git commit -m "docs: reorganize City of Data docs into EPIC_2.6"
```

### Task 7.2: Consolidate Archive

**Files:**
- Reorganize: `archive/` structure

**Step 1: Create epic-2-legacy directory**

```bash
mkdir -p archive/epic-2-legacy
```

**Step 2: Move MHD artifacts**

```bash
mv archive/mhd-parser archive/epic-2-legacy/ 2>/dev/null || true
mv archive/legacy-data archive/epic-2-legacy/ 2>/dev/null || true
mv archive/backend-core-nested archive/epic-2-legacy/ 2>/dev/null || true
```

**Step 3: Verify archive structure**

```bash
tree -L 2 archive/
```

Expected:
```
archive/
â””â”€â”€ epic-2-legacy/
    â”œâ”€â”€ mhd-parser/
    â”œâ”€â”€ legacy-data/
    â””â”€â”€ backend-core-nested/
```

**Step 4: Commit consolidation**

```bash
git add archive/
git commit -m "chore: consolidate Epic 2 legacy artifacts"
```

### Task 7.3: Update Progress Tracking

**Files:**
- Modify: `.claude/state/progress.json`
- Modify: `CLAUDE.md`

**Step 1: Update progress.json**

Edit `.claude/state/progress.json`:

```json
{
  "epic2_5_5": {
    "name": "Project Cleanup & JSON Migration Preparation",
    "status": "completed",
    "progress": 100,
    "tasks": [
      "âœ… Priority 1: Resolved duplicates & conflicts",
      "âœ… Priority 2: Removed MHD dependencies",
      "âœ… Priority 3: Updated Claude AI context",
      "âœ… Priority 4: Migrated Justfile commands",
      "âœ… Priority 5: Evaluated incomplete features",
      "âœ… Priority 6: Verified cleanup completeness",
      "âœ… Priority 7: Organizational housekeeping"
    ],
    "completion_date": "2025-11-XX",
    "github_issues_closed": ["#256"]
  }
}
```

**Step 2: Update CLAUDE.md**

Edit `CLAUDE.md` - UPDATE status:

```markdown
## ðŸ“Š Current Status

- **Epic 1**: âœ… Complete
- **Epic 2**: âœ… Complete
- **Epic 2.5.2**: âœ… Complete
- **Epic 2.5.3**: âœ… Complete
- **Epic 2.5.5**: âœ… Complete (Cleanup & JSON prep)
- **Epic 2.6**: ðŸ“‹ Ready to start (JSON migration)
- **Epic 3**: ðŸš§ 25% (API endpoints)
```

**Step 3: Commit updates**

```bash
git add .claude/state/progress.json CLAUDE.md
git commit -m "docs: mark Epic 2.5.5 as complete"
```

---

## Final Steps

### Task 8.1: Create Pull Request

**Step 1: Push branch**

```bash
git push -u origin feature/epic-2.5.5-cleanup
```

**Step 2: Create PR**

```bash
gh pr create \
  --title "Epic 2.5.5: Project Cleanup & JSON Migration Preparation" \
  --body "$(cat << 'EOF'
## Summary
Complete cleanup of MHD/I12 legacy code and preparation for JSON data migration.

## Changes
- âœ… Resolved duplicate backend/backend/app/core directory
- âœ… Archived legacy data directories
- âœ… Removed MHD parser module
- âœ… Created JSON import module
- âœ… Updated database models for JSON metadata
- âœ… Retrained Claude AI agents for JSON workflow
- âœ… Migrated Justfile commands
- âœ… Comprehensive cleanup verification

## Testing
- All tests passing
- Cleanup verification script passes
- No MHD references remain in code

## Documentation
- Updated import specialist guide
- Updated context map
- Documented all decisions in .claude/docs/EPIC_2.5.5/

## Blocks
- Unblocks Epic 2.6 (#253) - JSON Data Source Migration
- Unblocks Epic 2.7 (#254) - RAG Game Data Integration

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>
EOF
)"
```

**Step 3: Link to issues**

```bash
gh pr edit --add-label "epic,backend,documentation"
```

### Task 8.2: Close Epic Issue

**After PR is merged:**

```bash
gh issue close 256 --comment "Completed in PR #XXX. All priority tasks finished and verified."
```

---

## Verification Checklist

Run these commands to verify Epic 2.5.5 completion:

```bash
# 1. No MHD references in code
just verify-cleanup

# 2. All tests pass
just test

# 3. Quality checks pass
just quality

# 4. JSON import system healthy
just json-import-health

# 5. Health check passes
just health
```

All must pass before Epic 2.5.5 is considered complete.

---

## Success Criteria

- [x] `just verify-cleanup` passes with no errors
- [x] All duplicate directories resolved
- [x] MHD parser archived and references removed
- [x] JSON import module created with tests
- [x] Database models extended for JSON
- [x] Claude AI agents updated for JSON workflow
- [x] Justfile commands migrated
- [x] Calculation module assessed and handled
- [x] Documentation reorganized
- [x] All tests passing
- [x] Epic 2.6 ready to start

---

**Estimated Time**: 8 days (1 day per priority level)

**Next Epic**: Epic 2.6 - JSON Data Source Migration
